# 基于LRU算法的fabric框架改进研究

### 1. 要写一篇什么样的论文？

> ​     由于fabric的底层存储引擎为文件系统，当去进行记账与查询操作的时候，需要去区块索引获取到详细的信息，再去具体的文件块中读取到账本信息，查询的过程是使用socket进行通信的过程，这一过程比较耗时，尤其是对于一些高频信息的查询，所以，这里就设想为了提高fabric查询高频信息的速度，想在内存直接加入一个可维护的cache,用来存储高频访问的数据以及相对低频访问的数据，而这个cache的数据结构目前想借用LRU算法中的hash链表，简单来说就是当用户去查询一个数据的时候，这个数据就被放到hash链表的尾部，这样随着用户查询次数的层架，高频的数据就会聚集在hash链表的尾部，而头部则是聚集了相对低频的数据，当然，用户的访问账本的次数增加的时候，整个cache占的内存也会随着增加，这时候可以选择cache的空间大小，当超出这个cache的空间的时候，可以将从hash表的头开始删除相对低频的数据，这样就完成了一个可以维护的cache，可以提高高频数据的访问速度。

### 2. 首先上述的设计有哪些实际应用的场景，什么场景会频繁的访问高频数据？
> iot 物联网温度、湿度，风力大小等需要统计的场景，高频写入；
> smallBank、交易所，高频读取和写入，实时更新；
> 以上场景不符合要求。。。

> 涉及到高频查询，完全可以在 fabric 外一层设置 memcache， fabric 本身作为一个 kv 存储数据库， 拥有缓存的意义并不是很大（好像我想到的场景都是 写 高于 读， 而且写比读更耗时）

> 将 提高 写性能作为研究突破口， 应该会比 提高读性能更引人注目

### 3. 如果实际应用的场景对于单条数据的访问不够高频，那么我们是不是可以对数据进行高频类和低频类的区分，然后再对高频类数据进行cache处理。

### 4. 另外单加cache的论文肯定是创新点不足的，那么需要再提供两个优化点，另外数据量做足才可以。
